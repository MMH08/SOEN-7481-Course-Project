RemoveData
View(NoVarianceBlocks)
groupsInVectorFunctions = ZeroVariance_Functions %>%
filter(CloneGroupVariance == 0) %>%
select(CloneGroupType)
groupsInVectorFunctions
abcd = Answers_Mix_Model_tbl %>%
filter(Grunality == "Functions")
abcd
RemoveData1 = abcd %>%
filter((!CloneClassnumber %in% groupsInVectorFunctions) )
RemoveData1
RemoveData1 = abcd %>%
filter((CloneClassnumber %in% groupsInVectorFunctions) )
RemoveData1
# backup
explanatoryVariable = Answers_Mix_Model_tbl
names(explanatoryVariable)
summary(explanatoryVariable)
skewness(explanatoryVariable$A_length)
kurtosis(explanatoryVariable$A_length)
plot(hist(explanatoryVariable$A_Score)) #left Skewed
plot(hist(explanatoryVariable$A_TotalCodeLength))  #left Skewed
plot(hist(explanatoryVariable$A_NoOfBoldTags)) #left Skewed
plot(hist(explanatoryVariable$A_NoOfComments)) # replace null value with 0
plot(hist(explanatoryVariable$A_LinkTags)) #left Skewed
plot(hist(explanatoryVariable$A_NoOfEditOrRevision)) #left Skewed
plot(hist(explanatoryVariable$A_CodeRatioPercentage)) #right skewed
basic.lm <- lm( A_Score_Updated~A_length , data = explanatoryVariable)
summary(basic.lm)
library(ggplot2)  # load the package
(prelim_plot <- ggplot(explanatoryVariable, aes(x = A_length, y = A_Score_Updated)) +
geom_point() +
geom_smooth(method = "lm"))
Answers_Mix_Model_tbl = readr::read_csv("CloneDetection/asnwersFactorsNoZeroVariance.csv")
# backup
explanatoryVariable = Answers_Mix_Model_tbl
#CHECK DATA DISTRIBUTION
names(explanatoryVariable)
summary(explanatoryVariable)
skewness(explanatoryVariable$A_length)
kurtosis(explanatoryVariable$A_length)
plot(hist(explanatoryVariable$A_Score)) #left Skewed
plot(hist(explanatoryVariable$A_TotalCodeLength))  #left Skewed
plot(hist(explanatoryVariable$A_NoOfBoldTags)) #left Skewed
plot(hist(explanatoryVariable$A_NoOfComments)) # replace null value with 0
plot(hist(explanatoryVariable$A_LinkTags)) #left Skewed
plot(hist(explanatoryVariable$A_NoOfEditOrRevision)) #left Skewed
plot(hist(explanatoryVariable$A_CodeRatioPercentage)) #right skewed
basic.lm <- lm( A_Score_Updated~A_length , data = explanatoryVariable)
####### if the data is not normally distributed then follow this procedure
#replace with 0 values who have negative data
explanatoryVariable = explanatoryVariable %>%
mutate(A_Score_Updated = A_Score)
explanatoryVariable$A_Score_Updated <-
replace(explanatoryVariable$A_Score_Updated, which(explanatoryVariable$A_Score_Updated < 0), 0)
# increase by 1 in each column because with zero value the function can not be run it will provide error
explanatoryVariable$A_NoOfBoldTags = explanatoryVariable$A_NoOfBoldTags + 1
explanatoryVariable$A_NoOfCodeSnippets = explanatoryVariable$A_NoOfCodeSnippets + 1
explanatoryVariable$A_NoOfComments = explanatoryVariable$A_NoOfComments + 1
explanatoryVariable$A_NoOfEditOrRevision = explanatoryVariable$A_NoOfEditOrRevision + 1
explanatoryVariable$Answerer_ReputationScore = explanatoryVariable$Answerer_ReputationScore + 1
explanatoryVariable$Answerer_Upvotes = explanatoryVariable$Answerer_Upvotes + 1
explanatoryVariable$Answerer_DownVotes = explanatoryVariable$Answerer_DownVotes + 1
explanatoryVariable$Answerer_PostedQuestions = explanatoryVariable$Answerer_PostedQuestions + 1
explanatoryVariable$Answerer_PostedAnswers = explanatoryVariable$Answerer_PostedAnswers + 1
explanatoryVariable$Answerer_NoOfRevision = explanatoryVariable$Answerer_NoOfRevision + 1
explanatoryVariable$Answerer_NoOfRevisionInAnswer = explanatoryVariable$Answerer_NoOfRevisionInAnswer + 1
explanatoryVariable$A_CodeRatioPercentage = explanatoryVariable$A_CodeRatioPercentage + 1
explanatoryVariable$A_LinkTags = explanatoryVariable$A_LinkTags + 1
explanatoryVariable$A_ItalicTags = explanatoryVariable$A_ItalicTags + 1
explanatoryVariable$A_TotalCodeLength = explanatoryVariable$A_TotalCodeLength + 1
explanatoryVariable$A_codeRatio = explanatoryVariable$A_codeRatio + 1
explanatoryVariable$Answerer_25PercentileVotes = explanatoryVariable$Answerer_25PercentileVotes + 1
explanatoryVariable$Answerer_MinVotes = explanatoryVariable$Answerer_MinVotes + 1
explanatoryVariable$Answerer_MeanVotes = explanatoryVariable$Answerer_MeanVotes + 1
explanatoryVariable$Answerer_MedianVotes = explanatoryVariable$Answerer_MedianVotes + 1
explanatoryVariable$Answerer_MaxVotes = explanatoryVariable$Answerer_MaxVotes + 1
explanatoryVariable$Answerer_VarianceVotes = explanatoryVariable$Answerer_VarianceVotes + 1
explanatoryVariable$Answerer_25PercentileDwnVotes = explanatoryVariable$Answerer_25PercentileDwnVotes + 1
explanatoryVariable$Answerer_MinDwnVotes = explanatoryVariable$Answerer_MinDwnVotes + 1
explanatoryVariable$Answerer_MeanDwnVotes = explanatoryVariable$Answerer_MeanDwnVotes + 1
explanatoryVariable$Answerer_MedianDwnVotes = explanatoryVariable$Answerer_MedianDwnVotes + 1
explanatoryVariable$Answerer_MaxDwnVotes = explanatoryVariable$Answerer_MaxDwnVotes + 1
explanatoryVariable$Answerer_VarianceDwnVotes = explanatoryVariable$Answerer_VarianceDwnVotes + 1
explanatoryVariable$A_Score_Updated = explanatoryVariable$A_Score_Updated + 1
#### PQL is a flexible technique that can deal with non-normal data, unbalanced design, and crossed random effects.
PQL1 <- glmmPQL(A_Score_Updated ~ A_NoOfBoldTags + A_length+ A_NoOfCodeSnippets +A_NoOfComments+ A_NoOfEditOrRevision+
A_LinkTags + A_LinkTags + A_ItalicTags + A_TotalCodeLength + Answerer_ReputationScore +
Answerer_Upvotes + Answerer_DownVotes+ Answerer_PostedQuestions+Answerer_PostedAnswers+Answerer_NoOfRevision+Answerer_NoOfRevisionInAnswer+
A_CodeRatioPercentage + Answerer_25PercentileVotes +
Answerer_MinVotes +   Answerer_MeanVotes + Answerer_MedianVotes + Answerer_MaxVotes + Answerer_VarianceVotes +
Answerer_25PercentileDwnVotes + Answerer_MinDwnVotes + Answerer_MeanDwnVotes + Answerer_MedianDwnVotes + Answerer_MaxDwnVotes
+ Answerer_VarianceDwnVotes ,
~  1 | A_NoOfComments/A_TotalCodeLength,
family = poisson(link = "log"), data = explanatoryVariable, verbose = FALSE)
library(car)
library(MASS)
library(lme4)
library(mlmRev)
library(agridat)
library(MCMCglmm)
library(mlmRev)
library(ggplot2)
library(scapeMCMC)
library(nlme)
#install.packages("plotMCMC")
#install.packages('plotMCMC',repos='http://cran.us.r-project.org')
library(plotMCMC)
library(car)
library(MASS)
library(lme4)
library(mlmRev)
library(agridat)
library(MCMCglmm)
library(mlmRev)
library(ggplot2)
library(scapeMCMC)
library(nlme)
#install.packages("plotMCMC")
#install.packages('plotMCMC',repos='http://cran.us.r-project.org')
library(plotMCMC)
#### PQL is a flexible technique that can deal with non-normal data, unbalanced design, and crossed random effects.
PQL1 <- glmmPQL(A_Score_Updated ~ A_NoOfBoldTags + A_length+ A_NoOfCodeSnippets +A_NoOfComments+ A_NoOfEditOrRevision+
A_LinkTags + A_LinkTags + A_ItalicTags + A_TotalCodeLength + Answerer_ReputationScore +
Answerer_Upvotes + Answerer_DownVotes+ Answerer_PostedQuestions+Answerer_PostedAnswers+Answerer_NoOfRevision+Answerer_NoOfRevisionInAnswer+
A_CodeRatioPercentage + Answerer_25PercentileVotes +
Answerer_MinVotes +   Answerer_MeanVotes + Answerer_MedianVotes + Answerer_MaxVotes + Answerer_VarianceVotes +
Answerer_25PercentileDwnVotes + Answerer_MinDwnVotes + Answerer_MeanDwnVotes + Answerer_MedianDwnVotes + Answerer_MaxDwnVotes
+ Answerer_VarianceDwnVotes ,
~  1 | A_NoOfComments/A_TotalCodeLength,
family = poisson(link = "log"), data = explanatoryVariable, verbose = FALSE)
#### PQL is a flexible technique that can deal with non-normal data, unbalanced design, and crossed random effects.
PQL2 <- glmmPQL(A_Score_Updated ~ A_NoOfBoldTags + A_length+ A_NoOfCodeSnippets +A_NoOfComments+ A_NoOfEditOrRevision+
A_LinkTags + A_LinkTags + A_ItalicTags + A_TotalCodeLength + Answerer_ReputationScore +
Answerer_Upvotes + Answerer_DownVotes+ Answerer_PostedQuestions+Answerer_PostedAnswers+Answerer_NoOfRevision+Answerer_NoOfRevisionInAnswer+
A_CodeRatioPercentage + Answerer_25PercentileVotes +
Answerer_MinVotes +   Answerer_MeanVotes + Answerer_MedianVotes + Answerer_MaxVotes + Answerer_VarianceVotes +
Answerer_25PercentileDwnVotes + Answerer_MinDwnVotes + Answerer_MeanDwnVotes + Answerer_MedianDwnVotes + Answerer_MaxDwnVotes
+ Answerer_VarianceDwnVotes ,
~  1 | A_NoOfComments/A_TotalCodeLength,
family = gaussian(link = "identity"), data = explanatoryVariable, verbose = FALSE)
PQL3 <- glmmPQL(A_Score_Updated ~ A_NoOfBoldTags + A_length+ A_NoOfCodeSnippets +A_NoOfComments+ A_NoOfEditOrRevision+
A_LinkTags + A_LinkTags + A_ItalicTags + A_TotalCodeLength + Answerer_ReputationScore +
Answerer_Upvotes + Answerer_DownVotes+ Answerer_PostedQuestions+Answerer_PostedAnswers+Answerer_NoOfRevision+Answerer_NoOfRevisionInAnswer+
A_CodeRatioPercentage + Answerer_25PercentileVotes +
Answerer_MinVotes +   Answerer_MeanVotes + Answerer_MedianVotes + Answerer_MaxVotes + Answerer_VarianceVotes +
Answerer_25PercentileDwnVotes + Answerer_MinDwnVotes + Answerer_MeanDwnVotes + Answerer_MedianDwnVotes + Answerer_MaxDwnVotes
+ Answerer_VarianceDwnVotes ,
~  1 | A_NoOfComments/A_TotalCodeLength,
family = gaussian(link = "log"), data = explanatoryVariable, verbose = FALSE)
PQL4 <- glmmPQL(A_Score_Updated ~ A_NoOfBoldTags + A_length+ A_NoOfCodeSnippets +A_NoOfComments+ A_NoOfEditOrRevision+
A_LinkTags + A_LinkTags + A_ItalicTags + A_TotalCodeLength + Answerer_ReputationScore +
Answerer_Upvotes + Answerer_DownVotes+ Answerer_PostedQuestions+Answerer_PostedAnswers+Answerer_NoOfRevision+Answerer_NoOfRevisionInAnswer+
A_CodeRatioPercentage + Answerer_25PercentileVotes +
Answerer_MinVotes +   Answerer_MeanVotes + Answerer_MedianVotes + Answerer_MaxVotes + Answerer_VarianceVotes +
Answerer_25PercentileDwnVotes + Answerer_MinDwnVotes + Answerer_MeanDwnVotes + Answerer_MedianDwnVotes + Answerer_MaxDwnVotes
+ Answerer_VarianceDwnVotes ,
~  1 | A_NoOfComments/A_TotalCodeLength,
family = quasi(link = "identity", variance = "constant"), data = explanatoryVariable, verbose = FALSE)
summary(PQL1)
anova(PQL1,PQL2)
Anova(PQL1,PQL2)
Anova(PQL1)
AUC(PQL1)
library(pROC)
AUC(PQL1)
Anova(PQL2)
Anova(PQL3)
Anova(PQL4)
summary(PQL2)
summary(PQL3)
summary(PQL4)
Anova(PQL1)
Anova(PQL1)
Anova(PQL2)
Anova(PQL3)
summary(PQL1)
Anova(PQL1)
library(tidyverse)
library(lubridate)
# theme_tq()
library(tidyquant)
# Excel Files
library(readxl)
library(writexl)
library(dplyr)
library(stringr)
library(tidyverse)
library(lubridate)
library(forcats)
library(forcats)
library(dplyr)
library(ggplot2)
library(purrr)
library(recipes)
#install.packages("entropy")
library(entropy)
#############------------------Answers-------------##########
Mix_Model_csv_tbl = readr::read_csv("CloneDetection/A_Data_Mix_Model_CloneDetection.csv")
Mix_Model_csv_tbl %>%
dplyr::select( CloneClassType, CreateDate, Scores, Granularity) %>%
filter((CloneClassType == 2) & (Granularity == 'Functions'))
#Example for cloning changing the group and show the data
mixData = pull(Mix_Model_csv_tbl %>%
filter((CloneClassType == 7) & (Granularity == 'Functions')) %>%
select(Scores))
print(mixData)
#https://rstudio-pubs-static.s3.amazonaws.com/455435_30729e265f7a4d049400d03a18e218db.html
#compute Shannon entropy using functions
entropy <- function(target) {
freq <- table(target)/length(target)
# vectorize
vec <- as.data.frame(freq)[,2]
#drop 0 to avoid NaN resulting from log2
vec<-vec[vec>0]
#compute entropy
-sum(vec * log2(vec))
}
shannonEntropy <- function(counts.table, log.base = getOption("GeneFamilies.entropy.log.base",
base::exp(1))) {
if (length(counts.table) <= 1)
return(0)
c.t.s <- sum(counts.table)
-sum(sapply(counts.table, function(x) x/c.t.s * log(x/c.t.s, base = log.base)))/log(length(counts.table),
base = log.base)
}
##### ------- Answers Functions Clones ---------- #######
distinctClsFunc <- count(Mix_Model_csv_tbl %>%
filter((Granularity == 'Functions')) %>%
distinct(CloneClassType))
dat=matrix(nrow=2804,ncol=14)
dat=data.frame(dat)
for (i in 1:2804){
scoresInVector = pull(Mix_Model_csv_tbl %>%
filter((CloneClassType == i) & (Granularity == 'Functions')) %>%
dplyr::select(Scores))
print(length(scoresInVector))
dat[i,1]<- i
dat[i,2]<- 'Functions'
dat[i,3]<- format(round( as.numeric(format(quantile(scoresInVector,c(0.25)) , scientific=FALSE)), 2), nsmall = 2)
dat[i,4]<- format(round( as.numeric(format(max(scoresInVector) , scientific=FALSE)), 2), nsmall = 2)
dat[i,5]<- format(round( as.numeric(format(min(scoresInVector) , scientific=FALSE)), 2), nsmall = 2)
dat[i,6]<- format(round( as.numeric(format(mean(scoresInVector) , scientific=FALSE)), 2), nsmall = 2)
dat[i,7]<- format(round( as.numeric(format(median(scoresInVector) , scientific=FALSE)), 2), nsmall = 2)
# if(i == 553) {
#     dat[i,8]<- 0
#     print(i)
# }
# else
dat[i,8]<- format(round( as.numeric(format(var(scoresInVector) , scientific=FALSE)), 2), nsmall = 2)
dat[i,9]<- as.numeric(format(sqrt(var(scoresInVector)), scientific=FALSE));
dat[i,10]<- length(scoresInVector)
dat[i,11]<- entropy(scoresInVector)
dat[i,12]<- shannonEntropy (scoresInVector,2)
}
AnswerFunctionsDF = dat %>%
rename(
CloneGroupType = X1,
CloneGroupMax = X4,
CloneGroupMin = X5,
CloneGroupVariance = X8,
EachGroup_SD = X9,
EachGroup_Mean = X6,
EachGroup_Median = X7,
EachGroup_25Percentile = X3,
ShanonEntropy = X11,
NorShanonEntropy = X12
)
AnswerFunctionsDF = dat %>%
rename(
CloneGroupType = X1,
CloneGroupMax = X4,
CloneGroupMin = X5,
CloneGroupVariance = X8,
EachGroup_SD = X9,
EachGroup_Mean = X6,
EachGroup_Median = X7,
EachGroup_25Percentile = X3,
ShanonEntropy = X11,
NorShanonEntropy = X12
)
boxplot(as.numeric(AnswerFunctionsDF$CloneGroupVariance),
main = "Answer Functions: Boxlpot with 2,804 Group's Normalized Shannon  Entropy",
xlab = "2,804 Groups", ylab = "Each Group's Entropy of Votes ")
boxplot(as.numeric(AnswerFunctionsDF$CloneGroupVariance),
main = "Answer Functions: Boxlpot with 2,804 Group's Vote Varianc",
xlab = "2,804 Groups", ylab = "Each Group Vote Variancs ")
boxplot(as.numeric(AnswerFunctionsDF$NorShanonEntropy),
main = "Answer Functions: Boxlpot with 2,804 Group's Normalized Shannon  Entropy",
xlab = "2,804 Groups", ylab = "Each Group's Entropy of Votes ")
boxplot(as.numeric(AnswerFunctionsDF$NorShanonEntropy),
main = "Answer Functions: Boxlpot with 2,804 Group's Variance with Normalized Shannon Entropy",
xlab = "2,804 Groups", ylab = "Each Group Variance (Normalized Shannon Entropy) of Votes ")
##### ------- Questions Functions Clones  ---------- #######
distinctClsFunc <- count(Q_Mix_Model_csv_tbl %>%
filter((Granularity == 'Functions')) %>%
distinct(CloneClassType))
##### ------- Questions Blocks Clones  ---------- #######
Q_Mix_Model_csv_tbl = readr::read_csv("CloneDetection/Q_Data_Mix_Model_CloneDetection.csv")
##### ------- Questions Functions Clones  ---------- #######
distinctClsFunc <- count(Q_Mix_Model_csv_tbl %>%
filter((Granularity == 'Functions')) %>%
distinct(CloneClassType))
dat=matrix(nrow=16516,ncol=11)
dat=data.frame(dat)
for (i in 1:16516){
scoresInVector = pull(Q_Mix_Model_csv_tbl %>%
filter((CloneClassType == i) & (Granularity == 'Functions')) %>%
dplyr::select(Scores))
#print(length(scoresInVector))
dat[i,1]<- i
dat[i,2]<- 'Functions'
dat[i,3]<- format(quantile(scoresInVector,c(0.25)) , scientific=FALSE);
dat[i,4]<- format(min(scoresInVector), scientific=FALSE);
dat[i,5]<- format(max(scoresInVector), scientific=FALSE);
dat[i,6]<- format(mean(scoresInVector), scientific=FALSE);
dat[i,7]<- format(median(scoresInVector), scientific=FALSE);
variance = as.numeric(format(var(scoresInVector), scientific=FALSE))
if(variance >= 5000) {
dat[i,8]<- 0
print(variance)
}
else
dat[i,8]<- variance;
dat[i,9]<- format(sqrt(var(scoresInVector)), scientific=FALSE);
dat[i,10]<- length(scoresInVector)
dat[i,11]<- shannonEntropy (scoresInVector,2)
}
boxplot(as.numeric(AnswerFunctionsDF$ShannonEntropy),
main = "Question Functions: Boxlpot with 16,516 groups variance using Shannon Normalized Entropy ",
xlab = "16,516 Groups",ylab= "Each Group vote variance in Shannon Normalized Entropy")
boxplot(as.numeric(AnswerFunctionsDF$ShannonEntropy),
main = "Question Functions: Boxlpot with 16,516 groups variance using Shannon Normalized Entropy ",
xlab = "16,516 Groups",ylab= "Each Group vote variance in Shannon Normalized Entropy")
boxplot(as.numeric(AnswerFunctionsDF$ShannonEntropy),
main = "Question Functions: Boxlpot with 16,516 groups variance using Shannon Normalized Entropy ",
xlab = "16,516 Groups",ylab= "Each Group vote variance in Shannon Normalized Entropy")
AnswerFunctionsDF = dat %>%
rename(
CloneGroupType = X1,
CloneGroupMin = X4,
CloneGroupMax = X5,
CloneGroupVariance = X8,
EachGroup_SD = X9,
EachGroup_Mean = X6,
EachGroup_Median = X7,
EachGroup_25Percentile = X3,
ShannonEntropy = X11
)
boxplot(as.numeric(AnswerFunctionsDF$ShannonEntropy),
main = "Question Functions: Boxlpot with 16,516 groups variance using Shannon Normalized Entropy ",
xlab = "16,516 Groups",ylab= "Each Group vote variance in Shannon Normalized Entropy")
boxplot(as.numeric(AnswerFunctionsDF$CloneGroupVariance),
main = "Answer Functions: Boxlpot with 2,804 Group's Vote Variance",
xlab = "2,804 Groups", ylab = "Each Group Vote Variancs ")
##### ------- Answers Functions Clones ---------- #######
distinctClsFunc <- count(Mix_Model_csv_tbl %>%
filter((Granularity == 'Functions')) %>%
distinct(CloneClassType))
dat=matrix(nrow=2804,ncol=14)
dat=data.frame(dat)
for (i in 1:2804){
scoresInVector = pull(Mix_Model_csv_tbl %>%
filter((CloneClassType == i) & (Granularity == 'Functions')) %>%
dplyr::select(Scores))
print(length(scoresInVector))
dat[i,1]<- i
dat[i,2]<- 'Functions'
dat[i,3]<- format(round( as.numeric(format(quantile(scoresInVector,c(0.25)) , scientific=FALSE)), 2), nsmall = 2)
dat[i,4]<- format(round( as.numeric(format(max(scoresInVector) , scientific=FALSE)), 2), nsmall = 2)
dat[i,5]<- format(round( as.numeric(format(min(scoresInVector) , scientific=FALSE)), 2), nsmall = 2)
dat[i,6]<- format(round( as.numeric(format(mean(scoresInVector) , scientific=FALSE)), 2), nsmall = 2)
dat[i,7]<- format(round( as.numeric(format(median(scoresInVector) , scientific=FALSE)), 2), nsmall = 2)
# if(i == 553) {
#     dat[i,8]<- 0
#     print(i)
# }
# else
dat[i,8]<- format(round( as.numeric(format(var(scoresInVector) , scientific=FALSE)), 2), nsmall = 2)
dat[i,9]<- as.numeric(format(sqrt(var(scoresInVector)), scientific=FALSE));
dat[i,10]<- length(scoresInVector)
dat[i,11]<- entropy(scoresInVector)
dat[i,12]<- shannonEntropy (scoresInVector,2)
}
AnswerFunctionsDF = dat %>%
rename(
CloneGroupType = X1,
CloneGroupMax = X4,
CloneGroupMin = X5,
CloneGroupVariance = X8,
EachGroup_SD = X9,
EachGroup_Mean = X6,
EachGroup_Median = X7,
EachGroup_25Percentile = X3,
ShanonEntropy = X11,
NorShanonEntropy = X12
)
boxplot(as.numeric(AnswerFunctionsDF$CloneGroupVariance),
main = "Answer Functions: Boxlpot with 2,804 Group's Vote Variance",
xlab = "2,804 Groups", ylab = "Each Group Vote Variances ")
##### ------- Questions Functions Clones  ---------- #######
distinctClsFunc <- count(Q_Mix_Model_csv_tbl %>%
filter((Granularity == 'Functions')) %>%
distinct(CloneClassType))
dat=matrix(nrow=16516,ncol=11)
dat=data.frame(dat)
for (i in 1:16516){
scoresInVector = pull(Q_Mix_Model_csv_tbl %>%
filter((CloneClassType == i) & (Granularity == 'Functions')) %>%
dplyr::select(Scores))
#print(length(scoresInVector))
dat[i,1]<- i
dat[i,2]<- 'Functions'
dat[i,3]<- format(quantile(scoresInVector,c(0.25)) , scientific=FALSE);
dat[i,4]<- format(min(scoresInVector), scientific=FALSE);
dat[i,5]<- format(max(scoresInVector), scientific=FALSE);
dat[i,6]<- format(mean(scoresInVector), scientific=FALSE);
dat[i,7]<- format(median(scoresInVector), scientific=FALSE);
variance = as.numeric(format(var(scoresInVector), scientific=FALSE))
if(variance >= 5000) {
dat[i,8]<- 0
print(variance)
}
else
dat[i,8]<- variance;
dat[i,9]<- format(sqrt(var(scoresInVector)), scientific=FALSE);
dat[i,10]<- length(scoresInVector)
dat[i,11]<- shannonEntropy (scoresInVector,2)
}
AnswerFunctionsDF = dat %>%
rename(
CloneGroupType = X1,
CloneGroupMin = X4,
CloneGroupMax = X5,
CloneGroupVariance = X8,
EachGroup_SD = X9,
EachGroup_Mean = X6,
EachGroup_Median = X7,
EachGroup_25Percentile = X3,
ShannonEntropy = X11
)
boxplot(as.numeric(AnswerFunctionsDF$CloneGroupVariance),
main = "Answer Functions: Boxlpot with 2,804 Group's Vote Variance",
xlab = "2,804 Groups", ylab = "Each Group Vote Variances ")
boxplot(as.numeric(AnswerFunctionsDF$CloneGroupVariance),
main = "Question Functions: Boxlpot with 2,804 Group's Vote Variance",
xlab = "2,804 Groups", ylab = "Each Group Vote Variances ")
boxplot(as.numeric(AnswerFunctionsDF$CloneGroupVariance),
main = "Question Functions: Boxlpot with 16,516 Group's Vote Variance",
xlab = "16,516 Groups", ylab = "Each Group Vote Variances ")
##### ------- Answers Functions Clones ---------- #######
distinctClsFunc <- count(Mix_Model_csv_tbl %>%
filter((Granularity == 'Functions')) %>%
distinct(CloneClassType))
dat=matrix(nrow=2804,ncol=14)
dat=data.frame(dat)
for (i in 1:2804){
scoresInVector = pull(Mix_Model_csv_tbl %>%
filter((CloneClassType == i) & (Granularity == 'Functions')) %>%
dplyr::select(Scores))
print(length(scoresInVector))
dat[i,1]<- i
dat[i,2]<- 'Functions'
dat[i,3]<- format(round( as.numeric(format(quantile(scoresInVector,c(0.25)) , scientific=FALSE)), 2), nsmall = 2)
dat[i,4]<- format(round( as.numeric(format(max(scoresInVector) , scientific=FALSE)), 2), nsmall = 2)
dat[i,5]<- format(round( as.numeric(format(min(scoresInVector) , scientific=FALSE)), 2), nsmall = 2)
dat[i,6]<- format(round( as.numeric(format(mean(scoresInVector) , scientific=FALSE)), 2), nsmall = 2)
dat[i,7]<- format(round( as.numeric(format(median(scoresInVector) , scientific=FALSE)), 2), nsmall = 2)
# if(i == 553) {
#     dat[i,8]<- 0
#     print(i)
# }
# else
dat[i,8]<- format(round( as.numeric(format(var(scoresInVector) , scientific=FALSE)), 2), nsmall = 2)
dat[i,9]<- as.numeric(format(sqrt(var(scoresInVector)), scientific=FALSE));
dat[i,10]<- length(scoresInVector)
dat[i,11]<- entropy(scoresInVector)
dat[i,12]<- shannonEntropy (scoresInVector,2)
}
AnswerFunctionsDF = dat %>%
rename(
CloneGroupType = X1,
CloneGroupMax = X4,
CloneGroupMin = X5,
CloneGroupVariance = X8,
EachGroup_SD = X9,
EachGroup_Mean = X6,
EachGroup_Median = X7,
EachGroup_25Percentile = X3,
ShanonEntropy = X11,
NorShanonEntropy = X12
)
boxplot(as.numeric(AnswerFunctionsDF$CloneGroupVariance),
main = " Boxlpot with 2,804 Group's Vote Variance",
xlab = "2,804 Groups", ylab = "Each Group Vote Variances ")
Answers_Mix_Model_tbl
explanatoryVariable2
summary(PQL1)
Anova(PQL1)
QuestionClonedFactorsPart1 = readr::read_csv("CloneDetection/asnwersFactorsNoZeroVariance.csv")
QuestionClonedFactorsPart2 = readr::read_csv("CloneDetection/QuestionClonedFactorsData2.csv")
QuestionClonedDetectionFactors <- rbind(QuestionClonedFactorsPart1, QuestionClonedFactorsPart2)
QuestionClonedFactorsPart1 = readr::read_csv("CloneDetection/QuestionClonedFactorsData1.csv")
QuestionClonedFactorsPart2 = readr::read_csv("CloneDetection/QuestionClonedFactorsData2.csv")
QuestionClonedFactorsPart1 = readr::read_csv("CloneDetection/QuestionClonedFactorsData1.csv")
QuestionClonedFactorsPart2 = readr::read_csv("CloneDetection/QuestionClonedFactorsData2.csv")
QuestionClonedFactors <- rbind(QuestionClonedFactorsPart1, QuestionClonedFactorsPart2)
QuestionClonedFactors
Answers_Mix_Model_tbl = QuestionClonedFactors
Answers_Mix_Model_tbl
Questions_Mix_Model_tbl = QuestionClonedFactors
